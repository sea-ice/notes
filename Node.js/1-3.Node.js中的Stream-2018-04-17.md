Node.js中的Stream支持两种操作模式：

1. 二进制模式。在此模式下，流中的数据是以块的形式存在的，比如Buffer对象或者字符串；
2. 对象模式。在此模式下，流中的数据被看作是一系列独立的对象。

## Stream分类

Stream可以分为以下四类：

1. 可读流Readable

   可读流数据获取存在两种模式：
   （1）、非流动模式：当内部缓冲区有数据时，触发readable事件，在readable事件处理函数中通过read方法显式获取缓冲区中的数据；切换到non-flow模式的集中方式：
   a. 如果没有管道目标，调用 stream.pause() 方法；
   b. 如果有管道目标，移除所有管道目标。调用 stream.unpipe() 方法可以移除多个管道目标。
   （2）、流动模式：当内部缓冲区有数据时，触发data事件，在data事件处理函数中直接获取到数据。切换到flow模式的几种方式：
   a. 新增一个 'data' 事件处理函数;
   b. 调用 stream.resume() 方法;
   c. 调用 stream.pipe() 方法发送数据到可写流。

   自定义可读流类型需要定义\_read方法，在\_read方法中通过push方法将数据放到缓冲区中，最后通过push(null)来结束。如果在调用一次\_read方法中，如果出现多次调用push方法，则需要判断push方法的返回值是否为false，如果为false，则说明缓冲区中的数据超出了设定的highWaterMark的限制，因此需要暂停push。
   事件：
   （1）、readable事件
   （2）、data事件
   （3）、end事件
   （4）、error事件

   API：
   （1）、Readable.read([size])：从内部缓冲区读取size字节。默认情况下返回Buffer，除非之前调用了Readable.setEncoding()方法设置编码或流运行在对象模式。另外**调用read方法之后，还会触发可读流的data事件。**
   （2）、Readable.pipe(destination[, options])：返回目标流destination的引用。内部也是通过调用增强之后的on方法监听data事件，然后触发从当前可读流内部缓冲区中读取数据，同时将读取的数据写入到连接的目标流中。
   （3）、Readable.unpipe([destination])：如果不传入destination，则会分离所有绑定的目标流。同时分离的目标流还需要调用end方法手动进行关闭以避免内存泄漏。
   （3）、Readable.pause()：该方法会让处于Flowing模式下的流停止触发data事件
   （4）、Readable.resume()：让处于暂停态的可读流重新触发data事件

   默认在流动模式下，可读流一旦结束，会使得后续的流也自动结束，这时候向后面的流写入数据会导致错误，因此可以在调用可读流的pipe方法时传入{end: false}选项表示在可读流结束时不自动结束后续的可写流，之后需要手动关闭这些可写流以避免内存泄漏。

   可读流继承于Stream，同时Stream又继承于EventEmitter类，Readable类具有的on方法不同于普通的EventEmitter类的on监听方法，而是在EventEmitter类的on方法的基础上进行增强，该方法内部会调用read方法，使得流自动进入正常的工作方式。read(0)方法表示不需要读取数据，所以不会有数据返回，它的作用是可以启动流的正常工作（read -> \_read() -> push）。我们定义的\_read方法只有在read方法被调用时才可能被调用。

   push方法可以理解为向内部缓冲区填充数据，而read方法则是用来读取内部缓冲区中现有的数据，而read方法在读取内部缓冲区中的数据之前可能会调用\_read方法，\_read方法可能会向内部缓冲区填充更多的数据，前提是当前内部缓冲区中的数据还没有超出水位线。如果在t时刻的read方法读取之后的内部缓冲区中数据仍然会超出水位线，那么t时刻的这一次read方法调用中不会调用\_read方法向缓冲区写入新的数据。

   在non-flow模式下readable事件的触发时机：当内部缓冲区满的时候或者向空的缓冲区中push新数据的时候都会触发。另外在可读流刚开始工作的时候和在调用push(null)结束可读流之后也会各触发一次readable事件。代码示例：

   ```javascript
   let Chance = require('chance')
   const chance = new Chance()
   class RandomStream extends Readable {
      _read () {
         let chunk = chance.string()
         this.push(chunk)
         console.log(`Length: ${this._readableState.length}`)
      }
   }
   let rs = new RandomStream(), chunk
   rs.on('readable', function () {
      console.log('readable start')
      chunk = this.read()
      console.log(`read chunk: ${chunk}`)
   })
   ```

   每次调用read方法之后如果返回的数据不为空，不管是否处于flow模式下都会触发data事件的回调并将返回值作为回调的参数。

   如果push或者unshift方法传入的参数为null，则会设置state.ended为true，进而触发end事件。注意使用Readable时需要调用push(null)来结束可读流，否则\_read方法会被一直调用。

   References:
   [read, \_read, and readable: Readable Streams in Node.js](https://khanna.cc/blog/readable-streams-in-node-js/)

2. 可写流Writable
   
   可写流数据流向：可写流调用write方法 -> 将待写入的chunk传递给writeOrBuffer函数，检查当前缓冲区中的数据是否超出highWaterMark的限制，并设置needDrain标志位 -> 调用doWrite函数，内部调用需要开发者自定义的\_write方法，传入chunk、encoding、callback等参数，\_write方法内部执行callback时会根据前面设置的needDrain标志位（在数据长度超出highWaterMark）触发drain事件

   可写流存在一个背压（back pressure）问题，在调用write方法时会返回是否超出了初始时设置的highWaterMark值，然后再决定是否可以继续调用write方法。这是为了兼顾到消费者的消费速率。在没有调用end方法的前提下，在每一次执行write方法的最后，都会检查待写入的内容大小是否超出水位线，如果超出，则在被消费者消费（定义的\_write方法）之后会触发drain事件。在drain事件处理函数中可以继续调用write方法，提供数据供消费者消费。
   事件：
   （1）、pipe事件
   （2）、unpipe事件
   （3）、drain事件
   （4）、finish事件：可写流调用了end方法之后触发

   API：
   （1）、Writable.write(chunk[, encoding][, callback])
   （2）、Writable.end([chunk][, encoding][, callback])
  
3. 双向流Duplex
   
   双向流Duplex既是Readable，也是Writable。跟Readable和Writable一样，Duplex需要定义\_read和\_write方法。

4. 变换流Transform
   
   变换流Transform是一种特殊的双向流Duplex，内部已经实现了\_read和\_write方法，而与一般流不同的是，变换流Transform需要实现\_transform方法。

   正常工作流程是：write方法 -> \_write方法 -> \_read方法 -> \_transform方法，该方法会接收write方法传入的chunk、encoding参数以及转换完成的回调函数callback。该callback函数是内部定义的，外部需要传入可能出错时的err和新的data，如果传入了新的数据data，该callback内部会调用push方法，然后触发readable或者data事件；然后会调用前面write方法传入的回调函数，表示写入完成或失败；最后会调用\_read方法，注意Transform对象的\_write与\_read方法和Writable的\_write方法与Readable的\_read方法是不一样的。

   在自定义的\_transform方法中需要调用传入的转换完成的回调callback才能进行下一轮的转换。举例：

   ```javascript
   let {Readable, Transform} = require('stream')

   class CustomReadable extends Readable {
      _read () {
         this.push('a')
         this.push('b')
         this.push('c')
         this.push(null) // 如果没有调用push(null)，则当前可读流不会结束
      }
   }

   class CustomTransform extends Transform {
      _transform (chunk, encoding, next) {
         console.log(chunk.toString().toUpperCase())
         next() // 如果没有调用next，则会只转换第一次push过来的'a'
      }
   }

   let rs = new CustomReadable()
   let ts = new CustomTransform()
   rs.pipe(ts)
   ```

   转换流实现无序并列处理流，这种操作方式在对象流中很常见，而在二进制模式中几乎不会使用。

## 关于流的其他概念

### 组合流

组合流是由多个流构成的组合，对外表现为可读可写。本质上是组合流中的第一个流是可写流，最后一个流是可读流。除此之外，更重要的特点是必须能够捕获组合流中任何一个流触发的错误，但同时由于组合流对外表现为一个黑盒，所以外界只需要直接对组合流对象绑定一个错误监听函数即可，而不需要对组合流中的每一个流都进行绑定（由组合流内部自行完成绑定功能）。

### 复制流

复制流的含义是一个可读流中的内容可以通过多个管道传输到多个可写流中完成复制。可读流内部只维持一份读取状态，单个可读流连接的多个目标流每次触发的data事件都会拿到相同的数据。一旦可读流结束，连接的多个目标流也会自动结束。

### 合并流

合并流刚好和复制流相反，合并流是有多个可读流向单个可写流中写入数据，需要注意的是如果其中某个可读流结束，默认情况下可写流也会自动结束，所以需要等到所有的可读流都结束了，对应的可写流才能结束，也就需要关闭pipe方法的close选项的同时需要监听所有可读流的end事件，当所有可读流关闭了才能关闭目标流。另外如果合并流中传输的是二进制数据，这时候多个可读流的数据会随机混合到目标流中，这通常是不能接受的。

### 复用和分解

具体例子参照[这里](https://github.com/sea-ice/nodejs-code/tree/master/mux%26demux)